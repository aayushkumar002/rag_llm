{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a99463bd",
   "metadata": {},
   "source": [
    "### Introduction to Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9cc4e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "679673bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import (\n",
    "    RecursiveCharacterTextSplitter, \n",
    "    CharacterTextSplitter, \n",
    "    TokenTextSplitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afe5220",
   "metadata": {},
   "source": [
    "### Understand the document structure in langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "127276ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Structure:\n",
      "Content: This is a sample document for data ingestion.\n",
      "Metadata: {'source': 'sample_source.txt', 'author': 'Aayush'}\n"
     ]
    }
   ],
   "source": [
    "#create a sample document\n",
    "doc = Document(\n",
    "    page_content=\"This is a sample document for data ingestion.\",\n",
    "    metadata={\"source\": \"sample_source.txt\", \"author\": \"Aayush\"}\n",
    ")\n",
    "print(\"Document Structure:\")\n",
    "print(f\"Content: {doc.page_content}\")\n",
    "print(f\"Metadata: {doc.metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fde757",
   "metadata": {},
   "source": [
    "### Reading Text Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a3018e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a simple text file\n",
    "\n",
    "import os\n",
    "os.makedirs(\"data/text_files\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff3b81fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created sample text file at: data/text_files/sample2.txt\n"
     ]
    }
   ],
   "source": [
    "sample_texts = { \n",
    "    \"data/text_files/sample1.txt\": \n",
    "    \"\"\"This is the content of sample text file which has information about Langchain.\n",
    "    Langchain is a powerful library for building applications with LLMs.\n",
    "    It provides tools for data ingestion, parsing, and more.\n",
    "    And it is widely used in the AI community. What more, it supports various data formats.\n",
    "    Again it has information about text splitting techniques.\n",
    "    what else, it is very useful for developers working with large language models.\n",
    "    Additionally, it has a vibrant community and extensive documentation.\n",
    "    Developers can leverage Langchain to create innovative AI applications.\n",
    "    Finally, it is an open-source project that encourages contributions from the community.\n",
    "    Get started with Langchain today and explore its capabilities!\n",
    "    Happy coding with Langchain!\n",
    "    Just another line to increase the size of the file for testing purposes.\n",
    "    This line is added to ensure the file has enough content for text splitting demonstrations.\n",
    "    More lines to make the file larger.\n",
    "    Yet another line to enhance the sample text file.let's keep adding lines.\n",
    "    This should be sufficient for our current testing needs.\n",
    "    \"\"\",\n",
    "    \"data/text_files/sample2.txt\":\n",
    "    \"\"\"Another sample text file is created here.It contains different information.\n",
    "    This file talks about Python programming. Python is a versatile language used for web development, data science, automation, and more.\n",
    "    It has a rich ecosystem of libraries and frameworks that make development easier.\"\"\"\n",
    "    }\n",
    "for file_path, content in sample_texts.items():\n",
    "    with open(file_path, 'w', encoding=\"utf-8\") as f:\n",
    "        f.write(content)\n",
    "print(f\"Created sample text file at: {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459edab8",
   "metadata": {},
   "source": [
    "### TextLoader: Read Single File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a161a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[Document(metadata={'source': 'data/text_files/sample2.txt'}, page_content='Another sample text file is created here.It contains different information.\\n    This file talks about Python programming. Python is a versatile language used for web development, data science, automation, and more.\\n    It has a rich ecosystem of libraries and frameworks that make development easier.')]\n",
      "loaded 1 document(s).\n",
      "Content Preview: Another sample text file is created here.It contains different information.\n",
      "    This file talks abou\n",
      "metadata: {'source': 'data/text_files/sample2.txt'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "# Load the text file using Langchain's TextLoader\n",
    "\n",
    "loader = TextLoader(\"data/text_files/sample2.txt\", encoding = \"utf-8\")\n",
    "documents = loader.load()\n",
    "print(type(documents))\n",
    "print(documents)\n",
    "print(f\"loaded {len(documents)} document(s).\")\n",
    "print(f\"Content Preview: {documents[0].page_content[:100]}\")\n",
    "print(f\"metadata: {documents[0].metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b3f7a4",
   "metadata": {},
   "source": [
    "## DirectoryLoader - Multiple Text Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "990f3368",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 623.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document 1:\n",
      "Source: {'source': 'data\\\\text_files\\\\sample1.txt'}\n",
      "Content Preview: This is the content of sample text file which has \n",
      "length: 1149 characters\n",
      "\n",
      "Document 2:\n",
      "Source: {'source': 'data\\\\text_files\\\\sample2.txt'}\n",
      "Content Preview: Another sample text file is created here.It contai\n",
      "length: 300 characters\n",
      "\n",
      "Total documents loaded: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "# Load all text files from the directory\n",
    "dir_loader = DirectoryLoader(\n",
    "    \"data/text_files\",\n",
    "    glob=\"**/*.txt\", ##pattern to match files\n",
    "    loader_cls=TextLoader, ##loader class to use\n",
    "    loader_kwargs={\"encoding\": \"utf-8\"},\n",
    "    show_progress=True\n",
    ")\n",
    "all_documents = dir_loader.load()\n",
    "\n",
    "for i, document in enumerate(all_documents):\n",
    "    print(f\"\\nDocument {i+1}:\")\n",
    "    print(f\"Source: {document.metadata}\")\n",
    "    print(f\"Content Preview: {document.page_content[:50]}\")\n",
    "    print(f\"length: {len(document.page_content)} characters\")\n",
    "##why enumerate?\n",
    "#enumerate() adds a counter to an iterable and returns it as an enumerate object.\n",
    "# This is useful when you need both the index and the value from a list or other iterable.\n",
    "# In this case, it helps to number the documents as they are printed.\n",
    "# Without enumerate, you would have to manage a separate counter variable.\n",
    "# Using enumerate makes the code cleaner and more Pythonic.\n",
    "# It improves readability and reduces the chance of errors related to manual index management.\n",
    "print(f\"\\nTotal documents loaded: {len(all_documents)}\")\n",
    "\n",
    "## Major Disadvantage of DirectoryLoader: ALL FILES MUST BE OF SAME TYPE AND USE SAME LOADER CLASS#####"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7330846",
   "metadata": {},
   "source": [
    "## Text Splitting Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e101741f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'data\\\\text_files\\\\sample1.txt'}, page_content=\"This is the content of sample text file which has information about Langchain.\\n    Langchain is a powerful library for building applications with LLMs.\\n    It provides tools for data ingestion, parsing, and more.\\n    And it is widely used in the AI community. What more, it supports various data formats.\\n    Again it has information about text splitting techniques.\\n    what else, it is very useful for developers working with large language models.\\n    Additionally, it has a vibrant community and extensive documentation.\\n    Developers can leverage Langchain to create innovative AI applications.\\n    Finally, it is an open-source project that encourages contributions from the community.\\n    Get started with Langchain today and explore its capabilities!\\n    Happy coding with Langchain!\\n    Just another line to increase the size of the file for testing purposes.\\n    This line is added to ensure the file has enough content for text splitting demonstrations.\\n    More lines to make the file larger.\\n    Yet another line to enhance the sample text file.let's keep adding lines.\\n    This should be sufficient for our current testing needs.\\n    \"), Document(metadata={'source': 'data\\\\text_files\\\\sample2.txt'}, page_content='Another sample text file is created here.It contains different information.\\n    This file talks about Python programming. Python is a versatile language used for web development, data science, automation, and more.\\n    It has a rich ecosystem of libraries and frameworks that make development easier.')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import (\n",
    "    RecursiveCharacterTextSplitter, \n",
    "    CharacterTextSplitter, \n",
    "    TokenTextSplitter)\n",
    "print(all_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97826c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'data\\\\text_files\\\\sample1.txt'}, page_content=\"This is the content of sample text file which has information about Langchain.\\n    Langchain is a powerful library for building applications with LLMs.\\n    It provides tools for data ingestion, parsing, and more.\\n    And it is widely used in the AI community. What more, it supports various data formats.\\n    Again it has information about text splitting techniques.\\n    what else, it is very useful for developers working with large language models.\\n    Additionally, it has a vibrant community and extensive documentation.\\n    Developers can leverage Langchain to create innovative AI applications.\\n    Finally, it is an open-source project that encourages contributions from the community.\\n    Get started with Langchain today and explore its capabilities!\\n    Happy coding with Langchain!\\n    Just another line to increase the size of the file for testing purposes.\\n    This line is added to ensure the file has enough content for text splitting demonstrations.\\n    More lines to make the file larger.\\n    Yet another line to enhance the sample text file.let's keep adding lines.\\n    This should be sufficient for our current testing needs.\\n    \"), Document(metadata={'source': 'data\\\\text_files\\\\sample2.txt'}, page_content='Another sample text file is created here.It contains different information.\\n    This file talks about Python programming. Python is a versatile language used for web development, data science, automation, and more.\\n    It has a rich ecosystem of libraries and frameworks that make development easier.')]\n",
      "\n",
      "--- 1. Character Text Splitter ---\n",
      "Total Chunks Created: 7\n",
      "-----------------------------------\n",
      "['This is the content of sample text file which has information about Langchain.\\n    Langchain is a powerful library for building applications with LLMs.', 'It provides tools for data ingestion, parsing, and more.\\n    And it is widely used in the AI community. What more, it supports various data formats.', 'Again it has information about text splitting techniques.\\n    what else, it is very useful for developers working with large language models.', 'Additionally, it has a vibrant community and extensive documentation.\\n    Developers can leverage Langchain to create innovative AI applications.', 'Finally, it is an open-source project that encourages contributions from the community.\\n    Get started with Langchain today and explore its capabilities!\\n    Happy coding with Langchain!', 'Just another line to increase the size of the file for testing purposes.\\n    This line is added to ensure the file has enough content for text splitting demonstrations.', \"More lines to make the file larger.\\n    Yet another line to enhance the sample text file.let's keep adding lines.\\n    This should be sufficient for our current testing needs.\"]\n",
      "first chunk preview: This is the content of sample text file which has information about Langchain.\n",
      "    Langchain is a powerful library for building applications with LLMs.\n",
      "-----------------------------------\n",
      "second chunk preview: It provides tools for data ingestion, parsing, and more.\n",
      "    And it is widely used in the AI community. What more, it supports various data formats.\n"
     ]
    }
   ],
   "source": [
    "## Method 1: Character Text Splitter\n",
    "\n",
    "text = all_documents[0].page_content\n",
    "print(all_documents)\n",
    "print(\"\\n--- 1. Character Text Splitter ---\")\n",
    "char_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\", #Split at new lines\n",
    "    chunk_size=200, #max 200 characters per chunk\n",
    "    chunk_overlap=20, #20 characters overlap between chunks\n",
    "    length_function=len #function to measure length (len for characters\n",
    ")\n",
    "\n",
    "char_chunks = char_splitter.split_text(text)\n",
    "print(f\"Total Chunks Created: {len(char_chunks)}\")\n",
    "print(\"-----------------------------------\")\n",
    "print(char_chunks)\n",
    "print(f\"first chunk preview: {char_chunks[0]}\")\n",
    "print(\"-----------------------------------\")\n",
    "print(f\"second chunk preview: {char_chunks[1]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-project (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
